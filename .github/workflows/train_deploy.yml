name: Run the notebooks on data bricks workspace

on:
  push:
    branches:
      - main

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v2
        
      - name: Trigger notebook in workspace
        uses: databricks/run-notebook@v0
        with:
          databricks-host: https://adb-7150091277937564.4.azuredatabricks.net/
          databricks-token: ${{ secrets.DATABRICKS_TOKEN }}
          local-notebook-path: src/Libraries.py
          # The cluster JSON below is for AWS workspaces. On Azure and GCP, set
          # node_type_id to an appropriate node type, e.g. "Standard_D3_v2" for
          # Azure or "n1-highmem-4" for GCP
          new-cluster-json: >
            {
               "num_workers": 1,
               "spark_version": "11.3.x-scala2.12",
               "node_type_id": "Standard_D3_v2"
            }
